<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Patrick Dewey&#39;s Blog</title>
    <link>https://pdewey.com/blog</link>
    <description>Articles and thoughts from Patrick Dewey</description>
    <pubDate>Wed, 27 Nov 2024 16:03:29 -0500</pubDate>
    <item>
      <title>Adding Comments to My Blog with Bluesky!</title>
      <link>https://pdewey.com/blog/bluesky-comments-svelte</link>
      <description>&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Bluesky has been gaining a lot of traction and publicity recently, and there are a few aspects of the platform that have piqued my interest in a way that no other social media platform has done.&lt;/p&gt;&#xA;&lt;p&gt;What gets me most excited about Bluesky is that both the &lt;a href=&#34;https://bsky.app&#34;&gt;platform&lt;/a&gt; and the underlying &lt;a href=&#34;https://atproto.com/&#34;&gt;AT Protocol&lt;/a&gt; are open source&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. The open source nature of the platform is great for transparency (something other platforms sorely lack), and also makes it really easy for developers to improve on and build off of the platform. (The AT protocol is also very interesting and will likely enable many exciting projects in the future, but that&#39;s a topic for another day)&lt;/p&gt;&#xA;&lt;p&gt;What I&#39;d like to talk about today is one specific example of a tool that was built off of Bluesky, embeddable blog post comments.&lt;/p&gt;&#xA;&lt;h2&gt;Embedding Bluesky for Blog Comments&lt;/h2&gt;&#xA;&lt;p&gt;The idea of using Bluesky threads as blog comments was first debuted by &lt;a href=&#34;https://bsky.app/profile/emilyliu.me&#34;&gt;Emily Liu&lt;/a&gt; (a Bluesky developer) in a &lt;a href=&#34;https://emilyliu.me/blog/open-network&#34;&gt;post&lt;/a&gt; a couple of days ago. It quickly got people very excited, with many requests for example code.&lt;/p&gt;&#xA;&lt;p&gt;Fortunately, she published her code in a new &lt;a href=&#34;https://bsky.app/profile/emilyliu.me/post/3lbqta5lnck2i&#34;&gt;post&lt;/a&gt; the very next day. Unfortunately, her code&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; was built specifically around NextJS and TailwindCSS, but this code was enough of a starting point for me and (presumably) a number of other developers to start adapting it for other frameworks and applications.&lt;/p&gt;&#xA;&lt;p&gt;I found &lt;a href=&#34;https://bsky.app/profile/coryzue.com&#34;&gt;Cory Zue&#39;s&lt;/a&gt; implementation&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; in React pretty early on in its development, but I wasn&#39;t able to get it working with my site, as (at the time) the library only worked with React projects. As such, I set out to make my own version of the library in Svelte, since that is the framework I use for my site.&lt;/p&gt;&#xA;&lt;h3&gt;Building the Library&lt;/h3&gt;&#xA;&lt;p&gt;To begin, I used the Svelte library creation tool (&lt;code&gt;npx sv create&lt;/code&gt;) to set up a base project (I chose to use JavaScript and JSDoc for types).&lt;/p&gt;&#xA;&lt;p&gt;In a similar design to Emily Liu, I created Svelte components for &#39;Actions&#39;, &#39;Comments&#39;, and the &#39;CommentSection&#39;, with the &#39;CommentSection&#39; being the main exported component to be used in other pages. I wrote the component in a way that allows for either a post URI or a Bluesky handle to be used, with the handle option using the Bluesky API to find the most recent post containing the blog post URL (returning an error message if none are found).&lt;/p&gt;&#xA;&lt;p&gt;I set up some basic CSS styling for the components, and created some variables to allow styling of certain aspects to be outsourced to library users. This part of the library could likely be improved; I was unsure about which parts of the styling should be handled on the library&#39;s end instead of being delegated to users. I hope to address this soon (I&#39;d also very happily accept &lt;a href=&#34;https://github.com/ptdewey/bluesky-comments-svelte/issues&#34;&gt;feature requests&lt;/a&gt; and &lt;a href=&#34;https://github.com/ptdewey/bluesky-comments-svelte/pulls&#34;&gt;contributions&lt;/a&gt;).&lt;/p&gt;&#xA;&lt;p&gt;The last step was publishing the library so that I (and hopefully others) could use the library. I had never published an NPM package before, but the process was actually quite simple, as the library creation tool provided the necessary scripts. After running &lt;code&gt;npm package&lt;/code&gt; (and making some tweaks to &#39;package.json&#39;), my library was published to the NPM registry&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;. (The &lt;a href=&#34;https://github.com/ptdewey/bluesky-comments-svelte&#34;&gt;source code&lt;/a&gt; is also available&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;)&lt;/p&gt;&#xA;&lt;h2&gt;Integrating the Library Into My Site&lt;/h2&gt;&#xA;&lt;p&gt;To get the newly published library integrated with my site, all I had to do was install it:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;npm install bluesky-comments-svelte&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Import the component into my blog post &#39;+page.svelte&#39; file and set the author prop:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;script&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CommentSection&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;bluesky-comments-svelte&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;author&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;pdewey.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;script&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then add the component to the page itself:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Comments&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;div&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;comment-section&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;CommentSection&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;author&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;showCommentsTitle&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;false&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;div&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With just a few styling modifications (mostly colors), everything looked the way I wanted it.&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;root&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;--comment-border-color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;tan&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;--avatar-size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;rem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;--font-size-title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;rem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;--handle-color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;green&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;--comment-content-alignment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;flex-start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;--font-size-comment-body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;rem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;comment-section&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;brown&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;alt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;padding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;px&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;border-radius&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;px&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;style&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All that was left to take advantage of it was creating a new post (on the blog and on Bluesky)!&lt;/p&gt;&#xA;&lt;h2&gt;Closing Thoughts&lt;/h2&gt;&#xA;&lt;p&gt;Bluesky development feels like the wild west right now with many developers creating innovative new tools and integrations for and with the platform, and I&#39;m enjoying being a part of it. I had a lot of fun developing my library and learning about how the Bluesky API works, and I&#39;m quite happy with the result.&lt;/p&gt;&#xA;&lt;p&gt;If you use Svelte for your website, and want to integrate a comments section powered by Bluesky, give my library a try (and feel free to make suggestions that you think would improve the experience).&lt;br /&gt;&#xA;If you are not a Svelte user, but you want to add Bluesky comments, I also recommend Cory Zue&#39;s &lt;code&gt;bluesky-comments&lt;/code&gt; library which is available through NPM&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;, and I think it can be used with any framework now as well (although the bundle size is considerably bigger than the Svelte version if that is something you care about).&lt;/p&gt;&#xA;&lt;p&gt;Overall, this was a great learning experience, and I look forward to seeing all the cool stuff that gets built around Bluesky.&lt;/p&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr /&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;Bluesky appplication repository - &lt;a href=&#34;https://github.com/bluesky-social/social-app&#34;&gt;https://github.com/bluesky-social/social-app&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34;&gt;&#xA;&lt;p&gt;AT Protocol repository - &lt;a href=&#34;https://github.com/bluesky-social/atproto&#34;&gt;https://github.com/bluesky-social/atproto&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:3&#34;&gt;&#xA;&lt;p&gt;Emily Liu&#39;s comment code - &lt;a href=&#34;https://gist.github.com/emilyliu7321/19ac4e111588bdc0cb4e411c88d9c79a&#34;&gt;https://gist.github.com/emilyliu7321/19ac4e111588bdc0cb4e411c88d9c79a&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:4&#34;&gt;&#xA;&lt;p&gt;Cory Zue&#39;s comment library - &lt;a href=&#34;https://bsky.app/profile/coryzue.com/post/3lbrkypd37224&#34;&gt;https://bsky.app/profile/coryzue.com/post/3lbrkypd37224&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:5&#34;&gt;&#xA;&lt;p&gt;bluesky-comments-svelte NPM package - &lt;a href=&#34;https://www.npmjs.com/package/bluesky-comments-svelte&#34;&gt;https://www.npmjs.com/package/bluesky-comments-svelte&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:6&#34;&gt;&#xA;&lt;p&gt;My project repository - &lt;a href=&#34;https://github.com/ptdewey/bluesky-comments-svelte&#34;&gt;https://github.com/ptdewey/bluesky-comments-svelte&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:7&#34;&gt;&#xA;&lt;p&gt;Cory Zue&#39;s library (NPM) - &lt;a href=&#34;https://www.npmjs.com/package/bluesky-comments&#34;&gt;https://www.npmjs.com/package/bluesky-comments&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;&#xA;</description>
      <pubDate>2024-11-26</pubDate>
      <category>Software Development</category>
    </item>
    <item>
      <title>I rewrote my website in Svelte (and Go) and all I got was this lousy blog post</title>
      <link>https://pdewey.com/blog/i-rewrote-my-site-in-svelte</link>
      <description>&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;I have been using Hugo to run my personal website for a few years now, and it certainly did the job for me, but I was never truly happy with the aesthetics as I wanted something a bit more unique to me.&lt;br /&gt;&#xA;I could have just made my own theme, but Hugo&#39;s template system felt too complicated for what I actually wanted to do, so I decided I would start from scratch using a different tool.&lt;br /&gt;&#xA;Unfortunately, I do happen to be a fairly busy person (working and grad school and all), so I haven&#39;t had enough time to really jump in and build an entire site until this weekend when I had a bit of free time and a sudden (inexplicable) urge to try out Svelte.&lt;/p&gt;&#xA;&lt;h2&gt;Goals&lt;/h2&gt;&#xA;&lt;p&gt;I had a few goals/requirements that I wanted to meet before deploying the new site.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The site styling should be easy to customize and add to (pretty much just styling with CSS)&lt;/li&gt;&#xA;&lt;li&gt;I should be able to generate site content from markdown files (or a similar format like svx)&lt;/li&gt;&#xA;&lt;li&gt;Routing for pages generated from markdown files should be automatic or very simple&lt;/li&gt;&#xA;&lt;li&gt;The site should be styled based on my &lt;a href=&#34;https://github.com/ptdewey/darkearth-nvim&#34;&gt;DarkEarth&lt;/a&gt; color scheme (because its awesome)&lt;/li&gt;&#xA;&lt;li&gt;The site needs to be static and deployable on GitHub pages&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;The Rewrite&lt;/h2&gt;&#xA;&lt;p&gt;I started the rewrite by writing some CSS for the project, choosing the colors (based on DarkEarth) and designing a simple navbar.&lt;/p&gt;&#xA;&lt;p&gt;After this, I decided to build a small Go program that would convert Markdown files into HTML. I know there are JavaScript libraries I could have used for this, but I simply felt like writing some Go code (that&#39;s the only reason).&lt;br /&gt;&#xA;The Go program converts all Markdown files found in the &lt;code&gt;content&lt;/code&gt; directory into HTML files in &lt;code&gt;static&lt;/code&gt; and is built with the &amp;quot;goldmark&amp;quot; library.&lt;/p&gt;&#xA;&lt;p&gt;After this, I created a Svelte project, and spent some time learning how the page system works.&lt;br /&gt;&#xA;At first, the &lt;code&gt;+page.svelte&lt;/code&gt; and &lt;code&gt;+page.js&lt;/code&gt; filenames felt a bit strange, but after playing with Svelte a little bit, I really enjoyed how easy it was to create new pages and style them.&lt;br /&gt;&#xA;I particularly liked the layout system, where you create a &lt;code&gt;+layout.svelte&lt;/code&gt; file, which is then used in all pages lower in the file hierarchy.&lt;br /&gt;&#xA;This made it super easy for me to set up my navbar and load global CSS in a single place, without having to worry about adding them anywhere else.&lt;/p&gt;&#xA;&lt;p&gt;It took me a few hours to get everything the way I envisioned, and I also learned about MDsveX, a library that creates a markdown variant that allows the use of Svelte components in it.&lt;br /&gt;&#xA;I decided to give it a try in a couple of my pages (that were previously in Markdown), and it worked quite well with only a little bit of added configuration.&lt;/p&gt;&#xA;&lt;h2&gt;Closing Thoughts&lt;/h2&gt;&#xA;&lt;p&gt;The entire rewrite didn&#39;t take me nearly as long as I thought it would have, which is certainly somewhat due to Svelte&#39;s ease of use and simple syntax.&lt;br /&gt;&#xA;The GitHub pages deployment even worked on the first try!&lt;/p&gt;&#xA;&lt;p&gt;Overall, I&#39;m really happy with how the site turned out, and I plan to sporadically improve it going forward (it is much easier to customize now).&lt;br /&gt;&#xA;I also really enjoyed working with Svelte, which is something I&#39;ve never said about a frontend framework before, and as such, I highly recommend it if you are looking for a new web framework to try (for some reason).&lt;/p&gt;&#xA;&lt;p&gt;The code for this project can be found on GitHub &lt;a href=&#34;https://github.com/ptdewey/ptdewey.github.io&#34;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;</description>
      <pubDate>2024-11-10</pubDate>
      <category>Software Development</category>
    </item>
    <item>
      <title>A Review of &#34;The Signal and the Noise&#34;</title>
      <link>https://pdewey.com/blog/signal-and-the-noise</link>
      <description>&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;I&#39;m a bit late to the party when it comes to commentary on Nate Silver&#39;s book &lt;em&gt;the Signal and the Noise&lt;/em&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, but I recently finished reading it and I have a lot of thoughts about it.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/signal_and_noise_plot.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;h2&gt;Main Ideas&lt;/h2&gt;&#xA;&lt;p&gt;First, I want to say that I think it is an amazing book that is worth reading for anyone who is interested in statistics, practitioners and laymen alike. If you are considering reading it (and are reading my blog for some reason), I highly recommend it.&lt;br /&gt;&#xA;The main goal of the book is to investigate why &amp;quot;a vast majority of predictions fail&amp;quot; and to provide some tips to make better predictions.&lt;/p&gt;&#xA;&lt;p&gt;In the book, Silver discusses various case studies where predictions either fail or succeed, and explains the reasons behind these outcomes. This deep dive into each of the several subject areas he looked at focused on aspects of their systems that made them difficult (and sometimes impossible) to predict reliably using models, as well as the approaches that the model creators took when trying to generate predictions.&lt;br /&gt;&#xA;In his analysis, he repeatedly highlights a tendency for modelers to mistake noise (meaningless patterns present in the data) for signals (meaningful information we seek to extract and understand), leading to very poor predictive performance.&lt;br /&gt;&#xA;This tendency was especially common in fields where data is particularly noisy, or where signals are formed by extremely complex interactions between many different variables. In particular, he highlighted earthquake and stock market modeling as examples in which countless people have tried (and failed) to create reliable predictions about the future.&lt;/p&gt;&#xA;&lt;p&gt;Another important observation Silver made was that a common cause for bad predictions is the tendency for people to make predictions in accordance with the &amp;quot;herd mindset&amp;quot;. In cases like making predictions about the stock market or economy in particular, this tendency is very common, and can often result in bad predictions when the herd tries to be too safe or is too slow to adapt to broader environmental changes. When predicting economical swings, adhering to the herd has few downsides, whereas veering away can have dire consequences to someone&#39;s livelihood, especially if their prediction is wrong. Silver notes that this is because staying in the herd when predictions are wrong means everyone is wrong, whereas leaving the herd leaves you exposed without a herd to hide behind. While this can sometimes be good at preventing mass panics, this also has the unfortunate effect of disincentivizing astute analysts from showing off their findings, on the off chance they are wrong.&lt;/p&gt;&#xA;&lt;p&gt;He also highlighted cases where reliable models for prediction have been established--namely in baseball and weather forecasting--by finding ways to overcome the noise.&lt;br /&gt;&#xA;I found these chapters to be especially interesting, as both fields involved a vast set of different challenges that had to be overcome, with both fields eventually overcoming these challenges and producing impressive predictions (that we often take for granted in the case of the forecasts).&lt;br /&gt;&#xA;The story of how predictions finally started succeeding in weather forecasting stuck out to me as it is a problem that humans were trying to solve for hundreds (or thousands) of years, and we were only able to reliably do it in the last 70 through the convergence of many different fields (meteorology, physics, mathematics, statistics, and computing).&lt;/p&gt;&#xA;&lt;p&gt;In the back half of the book, he provides suggestions for how to make better predictions, passionately advocating for a much wider adoption of Bayesian statistical methodologies instead of traditionally used frequentist methods. This advocacy for Bayesian reasoning and inference is the main driving point throughout the book.&lt;/p&gt;&#xA;&lt;h2&gt;Bayesian Reasoning&lt;/h2&gt;&#xA;&lt;p&gt;Bayesian reasoning is a powerful, practical method of translating our beliefs about the world into actionable predictions, in a way that updates our understanding as new information becomes available. By combining prior knowledge with new evidence, Bayesian reasoning allows us to make more informed decisions, continuously refining our predictions to better reflect reality. This approach is very similar to the scientific method, where hypotheses are tested and updated based on experimental data. Both rely on an iterative process of forming expectations, gathering data, and revising beliefs, providing a systematic and intuitive framework for dealing with uncertainty&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Running parallel to the Bayesian methodology is the alternative methodological school of statistics, frequentism. Frequentist statistics is focused on long run frequencies for(hypothetical) probabilistic events, running in contrast to the Bayesian school which is focused more on single-event probabilities and the process of using and updating beliefs. Both methodologies have their merits, with both having their own strengths, but both I and Nate Silver consider ourselves Bayesians (although I land much closer to the middle than he presents himself).&lt;/p&gt;&#xA;&lt;p&gt;In the book, Silver takes the stance that applying Bayesian reasoning to the different situations he talks about would lead to better predictions that are reliant on fewer assumptions and are less likely to mistake noise for signal. He also posits that many success stories in the world of prediction result from the application of Bayesian thinking (whether that is intentional or simply through intuition).&lt;/p&gt;&#xA;&lt;p&gt;I would like to elaborate further on Bayesian reasoning, inference, and how it fits into the realm of machine learning in another post in the near future.&lt;/p&gt;&#xA;&lt;h2&gt;Criticisms&lt;/h2&gt;&#xA;&lt;p&gt;My main point on contention with Silver&#39;s point of view is the way that he positions the Bayesian methodology as wholly better than the frequentist alternative. While I would consider myself a Bayesian, I also understand that frequentist methods have their uses, particularly in cases where computational power is a limiting factor (Bayesian-based methods tend to be considerably more computationally intensive).&lt;/p&gt;&#xA;&lt;p&gt;I take issue with the way he asserts that we should entirely replace frequentist methods with Bayesian alternatives as a way of dealing with issues inherent to the frequentist approach (misinterpreting p-values, p-values close to the cutoff, misinterpreting confidence intervals, etc.). I don&#39;t disagree that these are very real issues that come up quite often (and often lead to bad science), and that Bayesian methods &lt;em&gt;could&lt;/em&gt; solve these issues. Unfortunately, the Bayesian approach is not without its own issues. The main criticism that can be brought against the methodology revolves around choice of the prior distribution, which can be viewed as overly arbitrary (and can lead to bad science when disingenuous choices are made). Since the Bayesian methodology is entirely focused on the process of using and updating beliefs, a choice of a very strong prior distribution can result in very inaccurate (unrepresentative or potentially even intentionally cherry-picked) results. On top of all this, frequentist and Bayesian methods are not even entirely mutually exclusive, and knowing when to use each can be a valuable skill in the field, regardless of which methodology you prefer (especially in machine learning contexts).&lt;/p&gt;&#xA;&lt;p&gt;Silver also states that the only bad choice of prior belief is no belief. I wholly disagree with this as priors can be overly strong (as previously mentioned), or can be based on little to no evidence. In cases lacking adequate data--whether as a result of personal experience or other reasons--a choice of an &lt;em&gt;uninformative&lt;/em&gt; prior would be the correct choice. Uninformative priors are types of prior distribution that are used in cases where we don&#39;t want to use any of our subjective beliefs and we want to make our Bayesian inferences as objectively as possible&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In one of the last case studies of the book, Silver discusses issues with climate modeling, as well as skepticism from experts and non-experts that result from models or their methodologies. This section includes a part where he compares models from two different sources, the IPCC (Intergovernmental Panel on Climate Change), and J. Scott Armstrong from the Heartland Institute (a conservative libertarian think tank). In this section of the book, Silver interviews Armstrong about his no-change model and his subsequent attempt to make a bet with Al Gore about the veracity of the IPCC model&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. At the time (2013), Armstrong&#39;s no change model (2009) was performing better than the IPCC&#39;s climate model (2007)&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; at predicting yearly change in global temperatures. The part of this I take issue with is how Silver heaps criticism onto the IPCC model about how it is overly complicated (which is partially true) and could be wrong, without applying any similar criticisms to Armstrong&#39;s model--a model produced by a conservative think tank with a history of producing dubious (and outright false) claims&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. Silver didn&#39;t even raise the obvious criticism that the &amp;quot;no-change&amp;quot; model chose a baseline global temperature of the hottest year on record at the time, 1998&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/temperature-change-plot.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;I would consider this baseline choice as particularly egregious as (with the full context of the above graph), it ignores a century of increasing global temperatures in order to serve a political narrative. This stuck out to me, partially as a young person who cares a lot about climate change, but also because I read the previous sections of this exact book, in which Silver calls out pundits for making predictions that serve their narrative, and are often incorrect as a result. I don&#39;t believe that Nate Silver is a climate denier by any means, but I do think it was harmful that he perpetuated the climate skepticism narrative by not applying adequate scrutiny to Armstrong&#39;s model.&lt;br /&gt;&#xA;I do acknowledge that it has been more than a decade since this book was written, but in hindsight this section has aged quite poorly. As of 2024, we have had the three hottest years on record back to back, and the annual global temperature changes are much more in line with the IPCC than with Armstrong&#39;s no change model (which looks pretty bad now&lt;sup id=&#34;fnref1:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;). As climate change continues to grow worse, writings like this section of the book are damaging to momentum towards dealing with the issue.&lt;/p&gt;&#xA;&lt;h2&gt;Final Thoughts&lt;/h2&gt;&#xA;&lt;p&gt;As I said before, I really enjoyed this book and the case studies it investigates. I found the explanation of the Bayesian methodology and how it meshes well with human intuition very interesting, as well as how Silver seeks to apply it to create better predictions. Other than a couple of notable critiques, my thoughts on the book are entirely positive, and I would highly recommend it to anyone interested in statistics. My beliefs about frequentist and Bayesian statistics shifted a bit more towards the Bayesian side in light of the new data (this book).&lt;br /&gt;&#xA;At the end of it all, I found this book to be a very interesting read, and I will continue to follow Silver&#39;s work&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt; of modeling elections and more.&lt;/p&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr /&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;The Signal and The Noise - &lt;a href=&#34;https://www.penguinrandomhouse.com/books/305826/the-signal-and-the-noise-by-nate-silver/&#34;&gt;https://www.penguinrandomhouse.com/books/305826/the-signal-and-the-noise-by-nate-silver/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34;&gt;&#xA;&lt;p&gt;Bayes Rules! An Introduction to Applied Bayesian Modeling - &lt;a href=&#34;https://www.bayesrulesbook.com&#34;&gt;https://www.bayesrulesbook.com&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:3&#34;&gt;&#xA;&lt;p&gt;Uninformative priors - &lt;a href=&#34;https://www.statlect.com/fundamentals-of-statistics/uninformative-prior&#34;&gt;https://www.statlect.com/fundamentals-of-statistics/uninformative-prior&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:4&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.researchgate.net/publication/349237629_The_Global_Warming_Challenge_Evidence-based_forecasting_for_climate_change_theclimatebetcom#fullTextFileContent&#34;&gt;https://www.researchgate.net/publication/349237629_The_Global_Warming_Challenge_Evidence-based_forecasting_for_climate_change_theclimatebetcom#fullTextFileContent&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:5&#34;&gt;&#xA;&lt;p&gt;IPCC report - &lt;a href=&#34;https://www.ipcc.ch/site/assets/uploads/2018/02/ar4_syr_full_report.pdf&#34;&gt;https://www.ipcc.ch/site/assets/uploads/2018/02/ar4_syr_full_report.pdf&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:6&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.politifact.com/personalities/heartland-institute/&#34;&gt;https://www.politifact.com/personalities/heartland-institute/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:7&#34;&gt;&#xA;&lt;p&gt;Change in global average temperature - &lt;a href=&#34;https://berkeleyearth.org/global-temperature-report-for-2023/&#34;&gt;https://berkeleyearth.org/global-temperature-report-for-2023/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:8&#34;&gt;&#xA;&lt;p&gt;Nate Silver&#39;s &lt;em&gt;Silver Bulletin&lt;/em&gt; Blog - &lt;a href=&#34;https://www.natesilver.net/&#34;&gt;https://www.natesilver.net/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;&#xA;</description>
      <pubDate>2024-05-21</pubDate>
      <category>Statistics</category>
    </item>
    <item>
      <title>Visually Representing *What* Neural Networks Learn</title>
      <link>https://pdewey.com/blog/neural-net-viz</link>
      <description>&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Recently, I just finished a semester-long project in which a colleague and I investigated how neural networks learn using visualizations. As a computer and data scientist, this topic has fascinated me for a while. We spend so much time constructing and refining neural networks, but very little time actually trying to understand how they work behind the scenes.&lt;/p&gt;&#xA;&lt;h2&gt;Background&lt;/h2&gt;&#xA;&lt;p&gt;Neural networks are inherently black-box models, meaning data goes in one side, and results come out the other. This is unfortunate, as it means that neither the developer nor the end user has any idea what is actually taking place within the network. This results in outputs that are often uninterpretable and can call into question whether or not the results are even trustworthy.&lt;/p&gt;&#xA;&lt;p&gt;This is a major problem, and it is only getting worse as we grow increasingly reliant on AI models in every aspect of our lives. It grows even worse when we take into account the fact that our models are becoming bigger and more complex, with the latest fascination being large language models (LLMs).&lt;/p&gt;&#xA;&lt;p&gt;Unfortunately, there is no simple solution to this issue, and even beginning to look into the learning process within a network requires an engaged effort from the creator. Our project began an investigation into methods through which neural networks could be visualized, with the goal of adding transparency to the model training process and turning AI into XAI (Explainable AI).&lt;/p&gt;&#xA;&lt;h3&gt;Project Scope&lt;/h3&gt;&#xA;&lt;p&gt;As this was a semester project, the scope had to be fairly limited. Most notably, we did not set out to try and set up a modular application in which any network could be visualized and instead focused on a few chosen datasets (to establish a prototype of sorts).&lt;/p&gt;&#xA;&lt;p&gt;We also only looked at classification networks, as regression networks are another animal entirely and would likely suffer from even more extreme interpretability issues than classifiers&lt;/p&gt;&#xA;&lt;h2&gt;Design Objectives and Decisions&lt;/h2&gt;&#xA;&lt;p&gt;Our approach to visualizing the learning process consisted of visualizing network weights (for image classification tasks) through the use of animated image plots. To create these plots, we plotted each weight in a layer as a single pixel in the image, with the color representing the value of that weight. Each image is made up of all the weights for a single neuron in a layer, and the images were arranged in a grid with all the images for that layer. To show how these weights evolve over the course of network training, we stitched the grid plots together into an animation.&lt;/p&gt;&#xA;&lt;p&gt;The other main component of our visualization of the learning process was visualizing network decision boundaries over time. To do this, we created a scatterplot of the data points and overlaid it on top of a contour plot representing the decision boundary of the network. In the scatterplot, the color of a point represents the class it is a part of. The colors of the contours are a bit harder to interpret (an area for improvement), but the dark red regions represent the actual decision boundary, and the network becomes more uncertain (represented as the color getting lighter, then changing to blue) as it gets farther away from the dark red region. Again, we wanted to show how the decision boundary changes during the training process, so we stitched the contour plots together into an animation.&lt;/p&gt;&#xA;&lt;h3&gt;Tools Used&lt;/h3&gt;&#xA;&lt;p&gt;To train our network and store the weights, we used Python with the PyTorch and SciKit-Learn libraries.&lt;br /&gt;&#xA;The weight and boundary visualizations were created in Python and animated using ffmpeg.&lt;br /&gt;&#xA;The exploratory PCA and &lt;em&gt;t&lt;/em&gt;-SNE plots were created with R and ggplot, with the 3-dimensional plots being made with ggplotly.&lt;br /&gt;&#xA;The overarching website was created using R-markdown, knit (compiled) to a couple of html pages, and then hosted using GitHub pages.&lt;/p&gt;&#xA;&lt;h2&gt;Results&lt;/h2&gt;&#xA;&lt;p&gt;The website for this project can be found at &lt;a href=&#34;https://pdewey.com/neural-net-viz&#34;&gt;https://pdewey.com/neural-net-viz&lt;/a&gt; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The source code for our code can also be found below &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;h3&gt;Visualizing Decision Boundaries&lt;/h3&gt;&#xA;&lt;p&gt;The decision boundary contour plot animations demonstrate how a neural network&#39;s decision boundary evolves and bisects the dataset it is trained on. Points represent the dataset, and the contoured background shows the decision boundary, with colors indicating the distance from the boundary. For example, using the Moons dataset, a highly nonlinear boundary is needed for correct classification.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-db-e1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Decision Boundary: Epoch 1&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The initial state of the decision boundary is completely random at the start of training.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-db-e20.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Decision Boundary: Epoch 20&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;After 20 epochs, the boundary has shaped to separate many of the points from each cluster, but it still misclassifies many entries at this point.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-db-e100.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Decision Boundary: Epoch 100&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;After 100 epochs, we can see that the decision boundary perfectly separates the two classes.&lt;/p&gt;&#xA;&lt;h3&gt;Dimensionality Reduction for High-Dimensional Datasets&lt;/h3&gt;&#xA;&lt;p&gt;The exploratory analysis page includes plots using Principal Component Analysis (PCA) and &lt;em&gt;t&lt;/em&gt;-Distributed Stochastic Neighbor Embedding (&lt;em&gt;t&lt;/em&gt;-SNE) to illustrate class distributions in the MNIST dataset. PCA plots show blurred boundaries between classes, while &lt;em&gt;t&lt;/em&gt;-SNE plots reveal distinct clusters and greater sensitivity to in-group differences. For both PCA and &lt;em&gt;t&lt;/em&gt;-SNE we included a biplot, de&lt;br /&gt;&#xA;nsity biplot, and 3D plot of the class embeddings.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-pca-biplots.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PCA Biplot and Density Biplot&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-tsne-biplots.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;t&lt;/em&gt;-SNE Biplot and Density Biplot&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Between the two dimensionality reduction algorithms, &lt;em&gt;t&lt;/em&gt;-SNE was better in this case at visually separating the classes from the dataset. We found the density biplot to be the most effective at visually communicating the distribution of the different data classes.&lt;/p&gt;&#xA;&lt;h3&gt;Visualizing Neuron Weights&lt;/h3&gt;&#xA;&lt;p&gt;Weight visualization animations show how neuron weights evolve during training for high-dimensional datasets like MNIST. Initially random, many of these weights gradually form (somewhat) recognizable patterns.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-wv-e1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Neuron Weights: Epoch 1&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-wv-e20.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Neuron Weights: Epoch 20&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;After 20 epochs, we can see a number of patterns that resemble entire numbers or parts of them.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nnviz-wv-e100.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Neuron Weights: Epoch 100&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;After 100 epochs, most weights became very muddled, still holding the previous patterns but in more muddy state. This may seem counterintuitive as the network appears (from the eyes of a human) to have lost the original patterns, but the network was performing noticeably better in classification tasks at the 100 epoch mark.&lt;/p&gt;&#xA;&lt;h2&gt;Limitations&lt;/h2&gt;&#xA;&lt;p&gt;A significant challenge in this project was visualizing high-dimensional data, decision boundaries, and weights. For instance, it wasn&#39;t possible to plot the decision boundary for the MNIST image classification dataset in a contour plot due to its high dimensionality. However, by using weight visualizations, it was possible to represent individual components of the decision boundary, offering insights into the network&#39;s behavior when trained on this dataset.&lt;br /&gt;&#xA;To address the dimensionality issue, PCA could be used to shrink the decision boundary into two or three dimensions, making visualization possible through contour plots. While this approach might produce messy or unclear results, it warrants further exploration and could yield intriguing findings.&lt;/p&gt;&#xA;&lt;p&gt;Another inherent limitation is that for large datasets with many unique output classes, weight visualizations often become unintelligible due to the wide range of possible weight values. This issue is more complex than the dimensionality problem but represents another potential area for future research.&lt;/p&gt;&#xA;&lt;h2&gt;Closing Thoughts&lt;/h2&gt;&#xA;&lt;p&gt;This project underscored the complexity of visualizing neural networks, especially when dealing with high-dimensional data. Despite the challenges, our efforts provided valuable insights into the learning processes of neural networks. By visualizing decision boundaries and neuron weights, we were able to peek into the black-box nature of these models and understand their behavior better.&lt;/p&gt;&#xA;&lt;p&gt;The techniques we used, like PCA and &lt;em&gt;t&lt;/em&gt;-SNE for dimensionality reduction, and animated weight visualizations, showed promise in making neural networks more interpretable. However, there are still significant limitations, especially in visualizing high-dimensional decision boundaries and weights for large datasets with many classes.&lt;/p&gt;&#xA;&lt;p&gt;Future research could explore more advanced dimensionality reduction techniques or develop new methods for visualizing neural networks. Our project is a step towards making AI models more transparent and trustworthy, contributing to the broader goal of Explainable AI (XAI). By continuing to innovate and experiment, we can hope to further demystify these powerful yet complex models.&lt;/p&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr /&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://pdewey.com/neural-net-viz/&#34;&gt;Project Site&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li id=&#34;fn:2&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ptdewey/neural-net-viz/&#34;&gt;Source Code&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;&#xA;</description>
      <pubDate>2024-05-13</pubDate>
      <category>Data Science, Programming</category>
    </item>
  </channel>
</rss>