[
  {
    "metadata": {
      "authors": [
        "Patrick Dewey"
      ],
      "categories": [
        "Statistics"
      ],
      "date": "2024-05-21",
      "draft": false,
      "slug": "signal-and-the-noise",
      "tags": [
        "statistics",
        "bayesian",
        "bayesian-statistics",
        "predictive-analytics",
        "book-review"
      ],
      "title": "A Review of \"The Signal and the Noise\""
    },
    "content": "\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eI'm a bit late to the party when it comes to commentary on Nate Silver's book \u003cem\u003ethe Signal and the Noise\u003c/em\u003e\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e, but I recently finished reading it and I have a lot of thoughts about it.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../signal_and_noise_plot.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003ch2\u003eMain Ideas\u003c/h2\u003e\n\u003cp\u003eFirst, I want to say that I think it is an amazing book that is worth reading for anyone who is interested in statistics, practitioners and laymen alike. If you are considering reading it (and are reading my blog for some reason), I highly recommend it.\u003cbr /\u003e\nThe main goal of the book is to investigate why \u0026quot;a vast majority of predictions fail\u0026quot; and to provide some tips to make better predictions.\u003c/p\u003e\n\u003cp\u003eIn the book, Silver discusses various case studies where predictions either fail or succeed, and explains the reasons behind these outcomes. This deep dive into each of the several subject areas he looked at focused on aspects of their systems that made them difficult (and sometimes impossible) to predict reliably using models, as well as the approaches that the model creators took when trying to generate predictions.\u003cbr /\u003e\nIn his analysis, he repeatedly highlights a tendency for modelers to mistake noise (meaningless patterns present in the data) for signals (meaningful information we seek to extract and understand), leading to very poor predictive performance.\u003cbr /\u003e\nThis tendency was especially common in fields where data is particularly noisy, or where signals are formed by extremely complex interactions between many different variables. In particular, he highlighted earthquake and stock market modeling as examples in which countless people have tried (and failed) to create reliable predictions about the future.\u003c/p\u003e\n\u003cp\u003eAnother important observation Silver made was that a common cause for bad predictions is the tendency for people to make predictions in accordance with the \u0026quot;herd mindset\u0026quot;. In cases like making predictions about the stock market or economy in particular, this tendency is very common, and can often result in bad predictions when the herd tries to be too safe or is too slow to adapt to broader environmental changes. When predicting economical swings, adhering to the herd has few downsides, whereas veering away can have dire consequences to someone's livelihood, especially if their prediction is wrong. Silver notes that this is because staying in the herd when predictions are wrong means everyone is wrong, whereas leaving the herd leaves you exposed without a herd to hide behind. While this can sometimes be good at preventing mass panics, this also has the unfortunate effect of disincentivizing astute analysts from showing off their findings, on the off chance they are wrong.\u003c/p\u003e\n\u003cp\u003eHe also highlighted cases where reliable models for prediction have been established--namely in baseball and weather forecasting--by finding ways to overcome the noise.\u003cbr /\u003e\nI found these chapters to be especially interesting, as both fields involved a vast set of different challenges that had to be overcome, with both fields eventually overcoming these challenges and producing impressive predictions (that we often take for granted in the case of the forecasts).\u003cbr /\u003e\nThe story of how predictions finally started succeeding in weather forecasting stuck out to me as it is a problem that humans were trying to solve for hundreds (or thousands) of years, and we were only able to reliably do it in the last 70 through the convergence of many different fields (meteorology, physics, mathematics, statistics, and computing).\u003c/p\u003e\n\u003cp\u003eIn the back half of the book, he provides suggestions for how to make better predictions, passionately advocating for a much wider adoption of Bayesian statistical methodologies instead of traditionally used frequentist methods. This advocacy for Bayesian reasoning and inference is the main driving point throughout the book.\u003c/p\u003e\n\u003ch2\u003eBayesian Reasoning\u003c/h2\u003e\n\u003cp\u003eBayesian reasoning is a powerful, practical method of translating our beliefs about the world into actionable predictions, in a way that updates our understanding as new information becomes available. By combining prior knowledge with new evidence, Bayesian reasoning allows us to make more informed decisions, continuously refining our predictions to better reflect reality. This approach is very similar to the scientific method, where hypotheses are tested and updated based on experimental data. Both rely on an iterative process of forming expectations, gathering data, and revising beliefs, providing a systematic and intuitive framework for dealing with uncertainty\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003cp\u003eRunning parallel to the Bayesian methodology is the alternative methodological school of statistics, frequentism. Frequentist statistics is focused on long run frequencies for(hypothetical) probabilistic events, running in contrast to the Bayesian school which is focused more on single-event probabilities and the process of using and updating beliefs. Both methodologies have their merits, with both having their own strengths, but both I and Nate Silver consider ourselves Bayesians (although I land much closer to the middle than he presents himself).\u003c/p\u003e\n\u003cp\u003eIn the book, Silver takes the stance that applying Bayesian reasoning to the different situations he talks about would lead to better predictions that are reliant on fewer assumptions and are less likely to mistake noise for signal. He also posits that many success stories in the world of prediction result from the application of Bayesian thinking (whether that is intentional or simply through intuition).\u003c/p\u003e\n\u003cp\u003eI would like to elaborate further on Bayesian reasoning, inference, and how it fits into the realm of machine learning in another post in the near future.\u003c/p\u003e\n\u003ch2\u003eCriticisms\u003c/h2\u003e\n\u003cp\u003eMy main point on contention with Silver's point of view is the way that he positions the Bayesian methodology as wholly better than the frequentist alternative. While I would consider myself a Bayesian, I also understand that frequentist methods have their uses, particularly in cases where computational power is a limiting factor (Bayesian-based methods tend to be considerably more computationally intensive).\u003c/p\u003e\n\u003cp\u003eI take issue with the way he asserts that we should entirely replace frequentist methods with Bayesian alternatives as a way of dealing with issues inherent to the frequentist approach (misinterpreting p-values, p-values close to the cutoff, misinterpreting confidence intervals, etc.). I don't disagree that these are very real issues that come up quite often (and often lead to bad science), and that Bayesian methods \u003cem\u003ecould\u003c/em\u003e solve these issues. Unfortunately, the Bayesian approach is not without its own issues. The main criticism that can be brought against the methodology revolves around choice of the prior distribution, which can be viewed as overly arbitrary (and can lead to bad science when disingenuous choices are made). Since the Bayesian methodology is entirely focused on the process of using and updating beliefs, a choice of a very strong prior distribution can result in very inaccurate (unrepresentative or potentially even intentionally cherry-picked) results. On top of all this, frequentist and Bayesian methods are not even entirely mutually exclusive, and knowing when to use each can be a valuable skill in the field, regardless of which methodology you prefer (especially in machine learning contexts).\u003c/p\u003e\n\u003cp\u003eSilver also states that the only bad choice of prior belief is no belief. I wholly disagree with this as priors can be overly strong (as previously mentioned), or can be based on little to no evidence. In cases lacking adequate data--whether as a result of personal experience or other reasons--a choice of an \u003cem\u003euninformative\u003c/em\u003e prior would be the correct choice. Uninformative priors are types of prior distribution that are used in cases where we don't want to use any of our subjective beliefs and we want to make our Bayesian inferences as objectively as possible\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003cp\u003eIn one of the last case studies of the book, Silver discusses issues with climate modeling, as well as skepticism from experts and non-experts that result from models or their methodologies. This section includes a part where he compares models from two different sources, the IPCC (Intergovernmental Panel on Climate Change), and J. Scott Armstrong from the Heartland Institute (a conservative libertarian think tank). In this section of the book, Silver interviews Armstrong about his no-change model and his subsequent attempt to make a bet with Al Gore about the veracity of the IPCC model\u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e. At the time (2013), Armstrong's no change model (2009) was performing better than the IPCC's climate model (2007)\u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e at predicting yearly change in global temperatures. The part of this I take issue with is how Silver heaps criticism onto the IPCC model about how it is overly complicated (which is partially true) and could be wrong, without applying any similar criticisms to Armstrong's model--a model produced by a conservative think tank with a history of producing dubious (and outright false) claims\u003csup id=\"fnref:6\"\u003e\u003ca href=\"#fn:6\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e6\u003c/a\u003e\u003c/sup\u003e. Silver didn't even raise the obvious criticism that the \u0026quot;no-change\u0026quot; model chose a baseline global temperature of the hottest year on record at the time, 1998\u003csup id=\"fnref:7\"\u003e\u003ca href=\"#fn:7\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e7\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../temperature-change-plot.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cp\u003eI would consider this baseline choice as particularly egregious as (with the full context of the above graph), it ignores a century of increasing global temperatures in order to serve a political narrative. This stuck out to me, partially as a young person who cares a lot about climate change, but also because I read the previous sections of this exact book, in which Silver calls out pundits for making predictions that serve their narrative, and are often incorrect as a result. I don't believe that Nate Silver is a climate denier by any means, but I do think it was harmful that he perpetuated the climate skepticism narrative by not applying adequate scrutiny to Armstrong's model.\u003cbr /\u003e\nI do acknowledge that it has been more than a decade since this book was written, but in hindsight this section has aged quite poorly. As of 2024, we have had the three hottest years on record back to back, and the annual global temperature changes are much more in line with the IPCC than with Armstrong's no change model (which looks pretty bad now\u003csup id=\"fnref1:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e). As climate change continues to grow worse, writings like this section of the book are damaging to momentum towards dealing with the issue.\u003c/p\u003e\n\u003ch2\u003eFinal Thoughts\u003c/h2\u003e\n\u003cp\u003eAs I said before, I really enjoyed this book and the case studies it investigates. I found the explanation of the Bayesian methodology and how it meshes well with human intuition very interesting, as well as how Silver seeks to apply it to create better predictions. Other than a couple of notable critiques, my thoughts on the book are entirely positive, and I would highly recommend it to anyone interested in statistics. My beliefs about frequentist and Bayesian statistics shifted a bit more towards the Bayesian side in light of the new data (this book).\u003cbr /\u003e\nAt the end of it all, I found this book to be a very interesting read, and I will continue to follow Silver's work\u003csup id=\"fnref:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e of modeling elections and more.\u003c/p\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr /\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003eThe Signal and The Noise - \u003ca href=\"https://www.penguinrandomhouse.com/books/305826/the-signal-and-the-noise-by-nate-silver/\"\u003ehttps://www.penguinrandomhouse.com/books/305826/the-signal-and-the-noise-by-nate-silver/\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\"\u003e\n\u003cp\u003eBayes Rules! An Introduction to Applied Bayesian Modeling - \u003ca href=\"https://www.bayesrulesbook.com\"\u003ehttps://www.bayesrulesbook.com\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:3\"\u003e\n\u003cp\u003eUninformative priors - \u003ca href=\"https://www.statlect.com/fundamentals-of-statistics/uninformative-prior\"\u003ehttps://www.statlect.com/fundamentals-of-statistics/uninformative-prior\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:3\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:4\"\u003e\n\u003cp\u003e\u003ca href=\"https://www.researchgate.net/publication/349237629_The_Global_Warming_Challenge_Evidence-based_forecasting_for_climate_change_theclimatebetcom#fullTextFileContent\"\u003ehttps://www.researchgate.net/publication/349237629_The_Global_Warming_Challenge_Evidence-based_forecasting_for_climate_change_theclimatebetcom#fullTextFileContent\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:4\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref1:4\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:5\"\u003e\n\u003cp\u003eIPCC report - \u003ca href=\"https://www.ipcc.ch/site/assets/uploads/2018/02/ar4_syr_full_report.pdf\"\u003ehttps://www.ipcc.ch/site/assets/uploads/2018/02/ar4_syr_full_report.pdf\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:5\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:6\"\u003e\n\u003cp\u003e\u003ca href=\"https://www.politifact.com/personalities/heartland-institute/\"\u003ehttps://www.politifact.com/personalities/heartland-institute/\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:6\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:7\"\u003e\n\u003cp\u003eChange in global average temperature - \u003ca href=\"https://berkeleyearth.org/global-temperature-report-for-2023/\"\u003ehttps://berkeleyearth.org/global-temperature-report-for-2023/\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:7\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:8\"\u003e\n\u003cp\u003eNate Silver's \u003cem\u003eSilver Bulletin\u003c/em\u003e Blog - \u003ca href=\"https://www.natesilver.net/\"\u003ehttps://www.natesilver.net/\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:8\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n"
  },
  {
    "metadata": {
      "authors": [
        "Patrick Dewey"
      ],
      "categories": [
        "Tech"
      ],
      "date": "2024-05-13",
      "draft": false,
      "slug": "neural-net-viz",
      "tags": [
        "machine-learning",
        "ai",
        "python",
        "r",
        "visualization"
      ],
      "title": "Visually Representing *What* Neural Networks Learn"
    },
    "content": "\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eRecently, I just finished a semester-long project in which a colleague and I investigated how neural networks learn using visualizations. As a computer and data scientist, this topic has fascinated me for a while. We spend so much time constructing and refining neural networks, but very little time actually trying to understand how they work behind the scenes.\u003c/p\u003e\n\u003ch2\u003eBackground\u003c/h2\u003e\n\u003cp\u003eNeural networks are inherently black-box models, meaning data goes in one side, and results come out the other. This is unfortunate, as it means that neither the developer nor the end user has any idea what is actually taking place within the network. This results in outputs that are often uninterpretable and can call into question whether or not the results are even trustworthy.\u003c/p\u003e\n\u003cp\u003eThis is a major problem, and it is only getting worse as we grow increasingly reliant on AI models in every aspect of our lives. It grows even worse when we take into account the fact that our models are becoming bigger and more complex, with the latest fascination being large language models (LLMs).\u003c/p\u003e\n\u003cp\u003eUnfortunately, there is no simple solution to this issue, and even beginning to look into the learning process within a network requires an engaged effort from the creator. Our project began an investigation into methods through which neural networks could be visualized, with the goal of adding transparency to the model training process and turning AI into XAI (Explainable AI).\u003c/p\u003e\n\u003ch3\u003eProject Scope\u003c/h3\u003e\n\u003cp\u003eAs this was a semester project, the scope had to be fairly limited. Most notably, we did not set out to try and set up a modular application in which any network could be visualized and instead focused on a few chosen datasets (to establish a prototype of sorts).\u003c/p\u003e\n\u003cp\u003eWe also only looked at classification networks, as regression networks are another animal entirely and would likely suffer from even more extreme interpretability issues than classifiers\u003c/p\u003e\n\u003ch2\u003eDesign Objectives and Decisions\u003c/h2\u003e\n\u003cp\u003eOur approach to visualizing the learning process consisted of visualizing network weights (for image classification tasks) through the use of animated image plots. To create these plots, we plotted each weight in a layer as a single pixel in the image, with the color representing the value of that weight. Each image is made up of all the weights for a single neuron in a layer, and the images were arranged in a grid with all the images for that layer. To show how these weights evolve over the course of network training, we stitched the grid plots together into an animation.\u003c/p\u003e\n\u003cp\u003eThe other main component of our visualization of the learning process was visualizing network decision boundaries over time. To do this, we created a scatterplot of the data points and overlaid it on top of a contour plot representing the decision boundary of the network. In the scatterplot, the color of a point represents the class it is a part of. The colors of the contours are a bit harder to interpret (an area for improvement), but the dark red regions represent the actual decision boundary, and the network becomes more uncertain (represented as the color getting lighter, then changing to blue) as it gets farther away from the dark red region. Again, we wanted to show how the decision boundary changes during the training process, so we stitched the contour plots together into an animation.\u003c/p\u003e\n\u003ch3\u003eTools Used\u003c/h3\u003e\n\u003cp\u003eTo train our network and store the weights, we used Python with the PyTorch and SciKit-Learn libraries.\u003cbr /\u003e\nThe weight and boundary visualizations were created in Python and animated using ffmpeg.\u003cbr /\u003e\nThe exploratory PCA and \u003cem\u003et\u003c/em\u003e-SNE plots were created with R and ggplot, with the 3-dimensional plots being made with ggplotly.\u003cbr /\u003e\nThe overarching website was created using R-markdown, knit (compiled) to a couple of html pages, and then hosted using GitHub pages.\u003c/p\u003e\n\u003ch2\u003eResults\u003c/h2\u003e\n\u003cp\u003eThe website for this project can be found at \u003ca href=\"https://pdewey.com/neural-net-viz\"\u003ehttps://pdewey.com/neural-net-viz\u003c/a\u003e \u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e. The source code for our code can also be found below \u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\u003ch3\u003eVisualizing Decision Boundaries\u003c/h3\u003e\n\u003cp\u003eThe decision boundary contour plot animations demonstrate how a neural network's decision boundary evolves and bisects the dataset it is trained on. Points represent the dataset, and the contoured background shows the decision boundary, with colors indicating the distance from the boundary. For example, using the Moons dataset, a highly nonlinear boundary is needed for correct classification.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-db-e1.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDecision Boundary: Epoch 1\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe initial state of the decision boundary is completely random at the start of training.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-db-e20.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDecision Boundary: Epoch 20\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAfter 20 epochs, the boundary has shaped to separate many of the points from each cluster, but it still misclassifies many entries at this point.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-db-e100.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDecision Boundary: Epoch 100\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAfter 100 epochs, we can see that the decision boundary perfectly separates the two classes.\u003c/p\u003e\n\u003ch3\u003eDimensionality Reduction for High-Dimensional Datasets\u003c/h3\u003e\n\u003cp\u003eThe exploratory analysis page includes plots using Principal Component Analysis (PCA) and \u003cem\u003et\u003c/em\u003e-Distributed Stochastic Neighbor Embedding (\u003cem\u003et\u003c/em\u003e-SNE) to illustrate class distributions in the MNIST dataset. PCA plots show blurred boundaries between classes, while \u003cem\u003et\u003c/em\u003e-SNE plots reveal distinct clusters and greater sensitivity to in-group differences. For both PCA and \u003cem\u003et\u003c/em\u003e-SNE we included a biplot, de\u003cbr /\u003e\nnsity biplot, and 3D plot of the class embeddings.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-pca-biplots.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePCA Biplot and Density Biplot\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-tsne-biplots.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003et\u003c/em\u003e-SNE Biplot and Density Biplot\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBetween the two dimensionality reduction algorithms, \u003cem\u003et\u003c/em\u003e-SNE was better in this case at visually separating the classes from the dataset. We found the density biplot to be the most effective at visually communicating the distribution of the different data classes.\u003c/p\u003e\n\u003ch3\u003eVisualizing Neuron Weights\u003c/h3\u003e\n\u003cp\u003eWeight visualization animations show how neuron weights evolve during training for high-dimensional datasets like MNIST. Initially random, many of these weights gradually form (somewhat) recognizable patterns.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-wv-e1.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNeuron Weights: Epoch 1\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-wv-e20.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNeuron Weights: Epoch 20\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAfter 20 epochs, we can see a number of patterns that resemble entire numbers or parts of them.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../nnviz-wv-e100.png\" alt=\"\" /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNeuron Weights: Epoch 100\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAfter 100 epochs, most weights became very muddled, still holding the previous patterns but in more muddy state. This may seem counterintuitive as the network appears (from the eyes of a human) to have lost the original patterns, but the network was performing noticeably better in classification tasks at the 100 epoch mark.\u003c/p\u003e\n\u003ch2\u003eLimitations\u003c/h2\u003e\n\u003cp\u003eA significant challenge in this project was visualizing high-dimensional data, decision boundaries, and weights. For instance, it wasn't possible to plot the decision boundary for the MNIST image classification dataset in a contour plot due to its high dimensionality. However, by using weight visualizations, it was possible to represent individual components of the decision boundary, offering insights into the network's behavior when trained on this dataset.\u003cbr /\u003e\nTo address the dimensionality issue, PCA could be used to shrink the decision boundary into two or three dimensions, making visualization possible through contour plots. While this approach might produce messy or unclear results, it warrants further exploration and could yield intriguing findings.\u003c/p\u003e\n\u003cp\u003eAnother inherent limitation is that for large datasets with many unique output classes, weight visualizations often become unintelligible due to the wide range of possible weight values. This issue is more complex than the dimensionality problem but represents another potential area for future research.\u003c/p\u003e\n\u003ch2\u003eClosing Thoughts\u003c/h2\u003e\n\u003cp\u003eThis project underscored the complexity of visualizing neural networks, especially when dealing with high-dimensional data. Despite the challenges, our efforts provided valuable insights into the learning processes of neural networks. By visualizing decision boundaries and neuron weights, we were able to peek into the black-box nature of these models and understand their behavior better.\u003c/p\u003e\n\u003cp\u003eThe techniques we used, like PCA and \u003cem\u003et\u003c/em\u003e-SNE for dimensionality reduction, and animated weight visualizations, showed promise in making neural networks more interpretable. However, there are still significant limitations, especially in visualizing high-dimensional decision boundaries and weights for large datasets with many classes.\u003c/p\u003e\n\u003cp\u003eFuture research could explore more advanced dimensionality reduction techniques or develop new methods for visualizing neural networks. Our project is a step towards making AI models more transparent and trustworthy, contributing to the broader goal of Explainable AI (XAI). By continuing to innovate and experiment, we can hope to further demystify these powerful yet complex models.\u003c/p\u003e\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr /\u003e\n\u003col\u003e\n\u003cli id=\"fn:1\"\u003e\n\u003cp\u003e\u003ca href=\"https://pdewey.com/neural-net-viz/\"\u003eProject Site\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:1\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli id=\"fn:2\"\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ptdewey/neural-net-viz/\"\u003eSource Code\u003c/a\u003e\u0026#160;\u003ca href=\"#fnref:2\" class=\"footnote-backref\" role=\"doc-backlink\"\u003e\u0026#x21a9;\u0026#xfe0e;\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n"
  }
]